{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Vgg16-Transfer Learning-COVID19.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCsf2vwqRkyYbnJy9sg0Zj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZVMKRh8itWoM","colab_type":"code","outputId":"6aef747f-221a-406d-9c8a-6e78a9f0be8b","executionInfo":{"status":"ok","timestamp":1585577669850,"user_tz":-300,"elapsed":58341,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GthfoQr39Koy","colab_type":"code","outputId":"c45e87d9-df2b-4cb1-b86f-3e3f5b2fcc36","executionInfo":{"status":"ok","timestamp":1585577721174,"user_tz":-300,"elapsed":51273,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","\n","%cd '/content/drive/My Drive/GitHub Repositories/COVID-19'\n","\n","dataDir = './datasets/dataset 01/Numpy Files'\n","train_x = np.load(dataDir+'/train_images.npy')\n","train_y = np.load(dataDir+'/train_labels.npy')\n","test_x = np.load(dataDir+'/test_images.npy')\n","test_y = np.load(dataDir+'/test_labels.npy')\n","\n","print('Training Images: {} | Test Images: {}'.format(train_x.shape, test_x.shape))\n","print('Training Labels: {} | Test Labels: {}'.format(train_y.shape, test_y.shape))\n","\n","# Data Normalization\n","\n","print('Train: {} , {} | Test: {} , {}'.format(train_x.min(), train_x.max(), test_x.min(), test_x.max()))\n","\n","train_x/=255.0\n","test_x/=255.0\n","\n","print('Train: {} , {} | Test: {} , {}'.format(train_x.min(), train_x.max(), test_x.min(), test_x.max()))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/GitHub Repositories/COVID-19\n","Training Images: (5310, 224, 224, 3) | Test Images: (639, 224, 224, 3)\n","Training Labels: (5310,) | Test Labels: (639,)\n","Train: 0.0 , 255.0 | Test: 0.0 , 255.0\n","Train: 0.0 , 1.0 | Test: 0.0 , 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OOL0OfPMJZ-f","colab_type":"code","outputId":"3cd6f2bb-8c1b-46eb-dd59-704e8adcfcd4","executionInfo":{"status":"ok","timestamp":1585577721186,"user_tz":-300,"elapsed":50560,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from collections import Counter\n","# Class Mapping \n","print('0:Normal | 1:Bacteria | 2:Viral | 3:COVID-19')\n","\n","# Distribution of images in each class for Training-set\n","print(Counter(train_y))\n","\n","# Distribution of images in each class for Test-set\n","print(Counter(test_y))\n","\n","#Make Labels Categorical\n","train_y_oneHot = tf.one_hot(train_y, depth=4) \n","test_y_oneHot = tf.one_hot(test_y, depth=4)\n","\n","print('Training Labels: {} | Test Labels: {}'.format(train_y_oneHot.shape, test_y_oneHot.shape))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0:Normal | 1:Bacteria | 2:Viral | 3:COVID-19\n","Counter({1: 2540, 2: 1355, 0: 1349, 3: 66})\n","Counter({1: 246, 0: 234, 2: 149, 3: 10})\n","Training Labels: (5310, 4) | Test Labels: (639, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LRA5FT_YLoJ2","colab_type":"code","outputId":"7ea85ecf-2113-497e-839b-f9b63f55f44b","executionInfo":{"status":"ok","timestamp":1585562581178,"user_tz":-300,"elapsed":4006,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# initialize the training data augmentation object\n","trainAug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")\n","\n","def VGG16_Model():\n","  # load the VGG16 network, ensuring the head FC layer sets are left off\n","  baseModel = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_tensor=tf.keras.layers.Input(shape=(224, 224, 3)))\n","  # construct the head of the model that will be placed on top of the the base model\n","  output = baseModel.output\n","  output = tf.keras.layers.AveragePooling2D(pool_size=(4, 4))(output)\n","  output = tf.keras.layers.Flatten(name=\"flatten\")(output)\n","  output = tf.keras.layers.Dense(64, activation=\"relu\")(output)\n","  output = tf.keras.layers.Dropout(0.5)(output)\n","  output = tf.keras.layers.Dense(4, activation=\"softmax\")(output)\n","  # place the head FC model on top of the base model (this will become the actual model we will train)\n","  model = tf.keras.Model(inputs=baseModel.input, outputs=output)\n","  # loop over all layers in the base model and freeze them so they will not be updated during the first training process\n","  for layer in baseModel.layers:\n","    layer.trainable = False\n","  return model\n","\n","model = VGG16_Model()\n","# compile our model\n","print(\"[INFO] compiling model...\")\n","# initialize the initial learning rate, number of epochs to train for, and batch size\n","INIT_LR = 0.001\n","EPOCHS = 100\n","BATCHSIZE = 32\n","optimizer = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n","print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","[INFO] compiling model...\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","average_pooling2d (AveragePo (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                32832     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 260       \n","=================================================================\n","Total params: 14,747,780\n","Trainable params: 33,092\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1FjXp4z9iOVK","colab_type":"code","outputId":"bbc3bc9b-79f0-480a-f5c4-5d540a816456","executionInfo":{"status":"ok","timestamp":1585568582801,"user_tz":-300,"elapsed":1946086,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["modelPath = './saved Models/Pretrained-VGG16'\n","if not os.path.exists(modelPath):\n","  os.makedirs(modelPath)\n","  print('Model Directory Created')\n","else:\n","  print('Model Directory Already Exists')\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('./saved Models/Pretrained-VGG16/normalized-best-model.h5', monitor='val_acc',\n","                                                      verbose=1, save_best_only=True, mode='auto')\n","STEP_TRAIN = len(train_x) // BATCHSIZE\n","STEP_TEST = len(test_x) // BATCHSIZE\n","\n","modelHistory = model.fit(trainAug.flow(train_x, train_y_oneHot, batch_size=BATCHSIZE), epochs=100, verbose=1, callbacks=[model_checkpoint],\n","                         validation_data=(test_x, test_y_oneHot), shuffle = True, steps_per_epoch=STEP_TRAIN, validation_steps=STEP_TEST)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model Directory Already Exists\n","Epoch 1/100\n","165/165 [==============================] - ETA: 0s - loss: 1.0547 - acc: 0.5174\n","Epoch 00001: val_acc improved from -inf to 0.59468, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 64s 391ms/step - loss: 1.0547 - acc: 0.5174 - val_loss: 0.9271 - val_acc: 0.5947\n","Epoch 2/100\n","165/165 [==============================] - ETA: 0s - loss: 0.8393 - acc: 0.6334\n","Epoch 00002: val_acc improved from 0.59468 to 0.62285, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 59s 360ms/step - loss: 0.8393 - acc: 0.6334 - val_loss: 0.8909 - val_acc: 0.6228\n","Epoch 3/100\n","165/165 [==============================] - ETA: 0s - loss: 0.7762 - acc: 0.6696\n","Epoch 00003: val_acc did not improve from 0.62285\n","165/165 [==============================] - 59s 357ms/step - loss: 0.7762 - acc: 0.6696 - val_loss: 0.8819 - val_acc: 0.6182\n","Epoch 4/100\n","165/165 [==============================] - ETA: 0s - loss: 0.7458 - acc: 0.6802\n","Epoch 00004: val_acc improved from 0.62285 to 0.65415, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 60s 363ms/step - loss: 0.7458 - acc: 0.6802 - val_loss: 0.8370 - val_acc: 0.6541\n","Epoch 5/100\n","165/165 [==============================] - ETA: 0s - loss: 0.7192 - acc: 0.6934\n","Epoch 00005: val_acc improved from 0.65415 to 0.66823, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 59s 359ms/step - loss: 0.7192 - acc: 0.6934 - val_loss: 0.8362 - val_acc: 0.6682\n","Epoch 6/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6831 - acc: 0.7156\n","Epoch 00006: val_acc did not improve from 0.66823\n","165/165 [==============================] - 59s 356ms/step - loss: 0.6831 - acc: 0.7156 - val_loss: 0.8634 - val_acc: 0.6682\n","Epoch 7/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6680 - acc: 0.7167\n","Epoch 00007: val_acc improved from 0.66823 to 0.75587, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 60s 366ms/step - loss: 0.6680 - acc: 0.7167 - val_loss: 0.7826 - val_acc: 0.7559\n","Epoch 8/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6583 - acc: 0.7171\n","Epoch 00008: val_acc did not improve from 0.75587\n","165/165 [==============================] - 59s 359ms/step - loss: 0.6583 - acc: 0.7171 - val_loss: 0.8277 - val_acc: 0.6854\n","Epoch 9/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6478 - acc: 0.7224\n","Epoch 00009: val_acc improved from 0.75587 to 0.76213, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 60s 362ms/step - loss: 0.6478 - acc: 0.7224 - val_loss: 0.7085 - val_acc: 0.7621\n","Epoch 10/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6335 - acc: 0.7306\n","Epoch 00010: val_acc did not improve from 0.76213\n","165/165 [==============================] - 59s 360ms/step - loss: 0.6335 - acc: 0.7306 - val_loss: 0.8903 - val_acc: 0.6886\n","Epoch 11/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6298 - acc: 0.7300\n","Epoch 00011: val_acc did not improve from 0.76213\n","165/165 [==============================] - 59s 358ms/step - loss: 0.6298 - acc: 0.7300 - val_loss: 0.7296 - val_acc: 0.7465\n","Epoch 12/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6197 - acc: 0.7391\n","Epoch 00012: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 361ms/step - loss: 0.6197 - acc: 0.7391 - val_loss: 0.7402 - val_acc: 0.7606\n","Epoch 13/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6073 - acc: 0.7370\n","Epoch 00013: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 363ms/step - loss: 0.6073 - acc: 0.7370 - val_loss: 0.7914 - val_acc: 0.7074\n","Epoch 14/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6086 - acc: 0.7353\n","Epoch 00014: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 362ms/step - loss: 0.6086 - acc: 0.7353 - val_loss: 0.8206 - val_acc: 0.7027\n","Epoch 15/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6037 - acc: 0.7433\n","Epoch 00015: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 362ms/step - loss: 0.6037 - acc: 0.7433 - val_loss: 0.7596 - val_acc: 0.7183\n","Epoch 16/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6035 - acc: 0.7389\n","Epoch 00016: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 363ms/step - loss: 0.6035 - acc: 0.7389 - val_loss: 0.8375 - val_acc: 0.7027\n","Epoch 17/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5843 - acc: 0.7457\n","Epoch 00017: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 366ms/step - loss: 0.5843 - acc: 0.7457 - val_loss: 0.8341 - val_acc: 0.7058\n","Epoch 18/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5931 - acc: 0.7452\n","Epoch 00018: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5931 - acc: 0.7452 - val_loss: 0.7936 - val_acc: 0.7324\n","Epoch 19/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5931 - acc: 0.7438\n","Epoch 00019: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5931 - acc: 0.7438 - val_loss: 0.8143 - val_acc: 0.6964\n","Epoch 20/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5820 - acc: 0.7471\n","Epoch 00020: val_acc did not improve from 0.76213\n","165/165 [==============================] - 60s 364ms/step - loss: 0.5820 - acc: 0.7471 - val_loss: 0.7706 - val_acc: 0.7543\n","Epoch 21/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5771 - acc: 0.7493\n","Epoch 00021: val_acc did not improve from 0.76213\n","165/165 [==============================] - 61s 370ms/step - loss: 0.5771 - acc: 0.7493 - val_loss: 0.7516 - val_acc: 0.7152\n","Epoch 22/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5739 - acc: 0.7560\n","Epoch 00022: val_acc improved from 0.76213 to 0.76995, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 62s 377ms/step - loss: 0.5739 - acc: 0.7560 - val_loss: 0.7430 - val_acc: 0.7700\n","Epoch 23/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5763 - acc: 0.7526\n","Epoch 00023: val_acc improved from 0.76995 to 0.77465, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 61s 370ms/step - loss: 0.5763 - acc: 0.7526 - val_loss: 0.6896 - val_acc: 0.7746\n","Epoch 24/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5714 - acc: 0.7545\n","Epoch 00024: val_acc did not improve from 0.77465\n","165/165 [==============================] - 60s 363ms/step - loss: 0.5714 - acc: 0.7545 - val_loss: 0.7234 - val_acc: 0.7496\n","Epoch 25/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5742 - acc: 0.7486\n","Epoch 00025: val_acc did not improve from 0.77465\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5742 - acc: 0.7486 - val_loss: 0.8330 - val_acc: 0.7261\n","Epoch 26/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5729 - acc: 0.7526\n","Epoch 00026: val_acc did not improve from 0.77465\n","165/165 [==============================] - 60s 363ms/step - loss: 0.5729 - acc: 0.7526 - val_loss: 0.7842 - val_acc: 0.7621\n","Epoch 27/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5706 - acc: 0.7573\n","Epoch 00027: val_acc did not improve from 0.77465\n","165/165 [==============================] - 60s 366ms/step - loss: 0.5706 - acc: 0.7573 - val_loss: 0.7480 - val_acc: 0.7512\n","Epoch 28/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5673 - acc: 0.7584\n","Epoch 00028: val_acc did not improve from 0.77465\n","165/165 [==============================] - 60s 366ms/step - loss: 0.5673 - acc: 0.7584 - val_loss: 0.7665 - val_acc: 0.7668\n","Epoch 29/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5559 - acc: 0.7577\n","Epoch 00029: val_acc did not improve from 0.77465\n","165/165 [==============================] - 60s 366ms/step - loss: 0.5559 - acc: 0.7577 - val_loss: 0.7898 - val_acc: 0.7590\n","Epoch 30/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5595 - acc: 0.7560\n","Epoch 00030: val_acc improved from 0.77465 to 0.78404, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 62s 373ms/step - loss: 0.5595 - acc: 0.7560 - val_loss: 0.7432 - val_acc: 0.7840\n","Epoch 31/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5501 - acc: 0.7664\n","Epoch 00031: val_acc did not improve from 0.78404\n","165/165 [==============================] - 60s 364ms/step - loss: 0.5501 - acc: 0.7664 - val_loss: 0.7539 - val_acc: 0.7543\n","Epoch 32/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5519 - acc: 0.7533\n","Epoch 00032: val_acc did not improve from 0.78404\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5519 - acc: 0.7533 - val_loss: 0.7024 - val_acc: 0.7543\n","Epoch 33/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5536 - acc: 0.7577\n","Epoch 00033: val_acc did not improve from 0.78404\n","165/165 [==============================] - 60s 366ms/step - loss: 0.5536 - acc: 0.7577 - val_loss: 0.9136 - val_acc: 0.7199\n","Epoch 34/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5568 - acc: 0.7584\n","Epoch 00034: val_acc improved from 0.78404 to 0.78717, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 61s 369ms/step - loss: 0.5568 - acc: 0.7584 - val_loss: 0.6686 - val_acc: 0.7872\n","Epoch 35/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5373 - acc: 0.7664\n","Epoch 00035: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5373 - acc: 0.7664 - val_loss: 0.7975 - val_acc: 0.7277\n","Epoch 36/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5415 - acc: 0.7641\n","Epoch 00036: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 363ms/step - loss: 0.5415 - acc: 0.7641 - val_loss: 0.8006 - val_acc: 0.7684\n","Epoch 37/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5473 - acc: 0.7666\n","Epoch 00037: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 364ms/step - loss: 0.5473 - acc: 0.7666 - val_loss: 0.7630 - val_acc: 0.7809\n","Epoch 38/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5504 - acc: 0.7569\n","Epoch 00038: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5504 - acc: 0.7569 - val_loss: 0.8353 - val_acc: 0.7496\n","Epoch 39/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5388 - acc: 0.7622\n","Epoch 00039: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 361ms/step - loss: 0.5388 - acc: 0.7622 - val_loss: 0.7414 - val_acc: 0.7668\n","Epoch 40/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5467 - acc: 0.7618\n","Epoch 00040: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 361ms/step - loss: 0.5467 - acc: 0.7618 - val_loss: 0.7298 - val_acc: 0.7746\n","Epoch 41/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5427 - acc: 0.7603\n","Epoch 00041: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5427 - acc: 0.7603 - val_loss: 0.8218 - val_acc: 0.7246\n","Epoch 42/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5347 - acc: 0.7662\n","Epoch 00042: val_acc did not improve from 0.78717\n","165/165 [==============================] - 59s 360ms/step - loss: 0.5347 - acc: 0.7662 - val_loss: 0.7613 - val_acc: 0.7559\n","Epoch 43/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5363 - acc: 0.7700\n","Epoch 00043: val_acc did not improve from 0.78717\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5363 - acc: 0.7700 - val_loss: 0.8496 - val_acc: 0.7559\n","Epoch 44/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5458 - acc: 0.7620\n","Epoch 00044: val_acc did not improve from 0.78717\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5458 - acc: 0.7620 - val_loss: 0.8671 - val_acc: 0.7606\n","Epoch 45/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5378 - acc: 0.7660\n","Epoch 00045: val_acc improved from 0.78717 to 0.79186, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 60s 366ms/step - loss: 0.5378 - acc: 0.7660 - val_loss: 0.6930 - val_acc: 0.7919\n","Epoch 46/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5361 - acc: 0.7609\n","Epoch 00046: val_acc did not improve from 0.79186\n","165/165 [==============================] - 61s 371ms/step - loss: 0.5361 - acc: 0.7609 - val_loss: 0.7161 - val_acc: 0.7653\n","Epoch 47/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5338 - acc: 0.7620\n","Epoch 00047: val_acc did not improve from 0.79186\n","165/165 [==============================] - 59s 358ms/step - loss: 0.5338 - acc: 0.7620 - val_loss: 0.7980 - val_acc: 0.7637\n","Epoch 48/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5300 - acc: 0.7698\n","Epoch 00048: val_acc did not improve from 0.79186\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5300 - acc: 0.7698 - val_loss: 0.7332 - val_acc: 0.7559\n","Epoch 49/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5311 - acc: 0.7732\n","Epoch 00049: val_acc did not improve from 0.79186\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5311 - acc: 0.7732 - val_loss: 0.8180 - val_acc: 0.7559\n","Epoch 50/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5355 - acc: 0.7626\n","Epoch 00050: val_acc improved from 0.79186 to 0.80438, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5355 - acc: 0.7626 - val_loss: 0.6685 - val_acc: 0.8044\n","Epoch 51/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5266 - acc: 0.7700\n","Epoch 00051: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 358ms/step - loss: 0.5266 - acc: 0.7700 - val_loss: 0.7482 - val_acc: 0.7574\n","Epoch 52/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5462 - acc: 0.7575\n","Epoch 00052: val_acc did not improve from 0.80438\n","165/165 [==============================] - 58s 353ms/step - loss: 0.5462 - acc: 0.7575 - val_loss: 0.7598 - val_acc: 0.7715\n","Epoch 53/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5200 - acc: 0.7764\n","Epoch 00053: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 358ms/step - loss: 0.5200 - acc: 0.7764 - val_loss: 0.7992 - val_acc: 0.7621\n","Epoch 54/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5272 - acc: 0.7700\n","Epoch 00054: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 355ms/step - loss: 0.5272 - acc: 0.7700 - val_loss: 0.8333 - val_acc: 0.7621\n","Epoch 55/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5343 - acc: 0.7662\n","Epoch 00055: val_acc did not improve from 0.80438\n","165/165 [==============================] - 58s 352ms/step - loss: 0.5343 - acc: 0.7662 - val_loss: 0.8903 - val_acc: 0.7355\n","Epoch 56/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5221 - acc: 0.7726\n","Epoch 00056: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 356ms/step - loss: 0.5221 - acc: 0.7726 - val_loss: 0.8228 - val_acc: 0.7621\n","Epoch 57/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5213 - acc: 0.7681\n","Epoch 00057: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 356ms/step - loss: 0.5213 - acc: 0.7681 - val_loss: 0.7692 - val_acc: 0.7825\n","Epoch 58/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5150 - acc: 0.7713\n","Epoch 00058: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 358ms/step - loss: 0.5150 - acc: 0.7713 - val_loss: 0.8894 - val_acc: 0.7199\n","Epoch 59/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5319 - acc: 0.7641\n","Epoch 00059: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 358ms/step - loss: 0.5319 - acc: 0.7641 - val_loss: 0.7911 - val_acc: 0.7653\n","Epoch 60/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5212 - acc: 0.7706\n","Epoch 00060: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 355ms/step - loss: 0.5212 - acc: 0.7706 - val_loss: 0.7218 - val_acc: 0.7496\n","Epoch 61/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5228 - acc: 0.7670\n","Epoch 00061: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 360ms/step - loss: 0.5228 - acc: 0.7670 - val_loss: 0.8652 - val_acc: 0.7653\n","Epoch 62/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5212 - acc: 0.7707\n","Epoch 00062: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 357ms/step - loss: 0.5212 - acc: 0.7707 - val_loss: 0.7991 - val_acc: 0.7778\n","Epoch 63/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5286 - acc: 0.7671\n","Epoch 00063: val_acc did not improve from 0.80438\n","165/165 [==============================] - 61s 370ms/step - loss: 0.5286 - acc: 0.7671 - val_loss: 0.6999 - val_acc: 0.7934\n","Epoch 64/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5115 - acc: 0.7791\n","Epoch 00064: val_acc did not improve from 0.80438\n","165/165 [==============================] - 62s 378ms/step - loss: 0.5115 - acc: 0.7791 - val_loss: 0.8218 - val_acc: 0.7574\n","Epoch 65/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5150 - acc: 0.7721\n","Epoch 00065: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5150 - acc: 0.7721 - val_loss: 0.8737 - val_acc: 0.7637\n","Epoch 66/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5257 - acc: 0.7687\n","Epoch 00066: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5257 - acc: 0.7687 - val_loss: 0.7525 - val_acc: 0.7621\n","Epoch 67/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4971 - acc: 0.7806\n","Epoch 00067: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 357ms/step - loss: 0.4971 - acc: 0.7806 - val_loss: 0.9342 - val_acc: 0.7324\n","Epoch 68/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5275 - acc: 0.7653\n","Epoch 00068: val_acc did not improve from 0.80438\n","165/165 [==============================] - 61s 371ms/step - loss: 0.5275 - acc: 0.7653 - val_loss: 0.7555 - val_acc: 0.7840\n","Epoch 69/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5051 - acc: 0.7806\n","Epoch 00069: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5051 - acc: 0.7806 - val_loss: 0.6810 - val_acc: 0.7778\n","Epoch 70/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5162 - acc: 0.7704\n","Epoch 00070: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 360ms/step - loss: 0.5162 - acc: 0.7704 - val_loss: 0.8056 - val_acc: 0.7746\n","Epoch 71/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5197 - acc: 0.7673\n","Epoch 00071: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 360ms/step - loss: 0.5197 - acc: 0.7673 - val_loss: 0.7355 - val_acc: 0.7402\n","Epoch 72/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5079 - acc: 0.7783\n","Epoch 00072: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 361ms/step - loss: 0.5079 - acc: 0.7783 - val_loss: 0.7412 - val_acc: 0.7543\n","Epoch 73/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5181 - acc: 0.7698\n","Epoch 00073: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 357ms/step - loss: 0.5181 - acc: 0.7698 - val_loss: 0.7325 - val_acc: 0.7872\n","Epoch 74/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4997 - acc: 0.7743\n","Epoch 00074: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 357ms/step - loss: 0.4997 - acc: 0.7743 - val_loss: 0.8225 - val_acc: 0.7809\n","Epoch 75/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5094 - acc: 0.7654\n","Epoch 00075: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 357ms/step - loss: 0.5094 - acc: 0.7654 - val_loss: 0.7719 - val_acc: 0.7637\n","Epoch 76/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5155 - acc: 0.7734\n","Epoch 00076: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 358ms/step - loss: 0.5155 - acc: 0.7734 - val_loss: 0.8552 - val_acc: 0.7433\n","Epoch 77/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5181 - acc: 0.7683\n","Epoch 00077: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 361ms/step - loss: 0.5181 - acc: 0.7683 - val_loss: 0.8935 - val_acc: 0.7340\n","Epoch 78/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5046 - acc: 0.7812\n","Epoch 00078: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5046 - acc: 0.7812 - val_loss: 0.7255 - val_acc: 0.7825\n","Epoch 79/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5196 - acc: 0.7635\n","Epoch 00079: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 361ms/step - loss: 0.5196 - acc: 0.7635 - val_loss: 0.8279 - val_acc: 0.7653\n","Epoch 80/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5071 - acc: 0.7761\n","Epoch 00080: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 361ms/step - loss: 0.5071 - acc: 0.7761 - val_loss: 0.8326 - val_acc: 0.7574\n","Epoch 81/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5081 - acc: 0.7736\n","Epoch 00081: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 360ms/step - loss: 0.5081 - acc: 0.7736 - val_loss: 0.6477 - val_acc: 0.7997\n","Epoch 82/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5179 - acc: 0.7753\n","Epoch 00082: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 363ms/step - loss: 0.5179 - acc: 0.7753 - val_loss: 0.8739 - val_acc: 0.7371\n","Epoch 83/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4978 - acc: 0.7709\n","Epoch 00083: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 363ms/step - loss: 0.4978 - acc: 0.7709 - val_loss: 0.7808 - val_acc: 0.7793\n","Epoch 84/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5066 - acc: 0.7787\n","Epoch 00084: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 362ms/step - loss: 0.5066 - acc: 0.7787 - val_loss: 0.8122 - val_acc: 0.7684\n","Epoch 85/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5051 - acc: 0.7831\n","Epoch 00085: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5051 - acc: 0.7831 - val_loss: 0.6613 - val_acc: 0.7887\n","Epoch 86/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5144 - acc: 0.7787\n","Epoch 00086: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5144 - acc: 0.7787 - val_loss: 0.8143 - val_acc: 0.7606\n","Epoch 87/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5037 - acc: 0.7698\n","Epoch 00087: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 363ms/step - loss: 0.5037 - acc: 0.7698 - val_loss: 0.8400 - val_acc: 0.7621\n","Epoch 88/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4917 - acc: 0.7893\n","Epoch 00088: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 366ms/step - loss: 0.4917 - acc: 0.7893 - val_loss: 0.7728 - val_acc: 0.7715\n","Epoch 89/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5104 - acc: 0.7781\n","Epoch 00089: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 364ms/step - loss: 0.5104 - acc: 0.7781 - val_loss: 0.7737 - val_acc: 0.7746\n","Epoch 90/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5048 - acc: 0.7770\n","Epoch 00090: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 365ms/step - loss: 0.5048 - acc: 0.7770 - val_loss: 0.8464 - val_acc: 0.7402\n","Epoch 91/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4917 - acc: 0.7812\n","Epoch 00091: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 361ms/step - loss: 0.4917 - acc: 0.7812 - val_loss: 0.8811 - val_acc: 0.7418\n","Epoch 92/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5074 - acc: 0.7806\n","Epoch 00092: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5074 - acc: 0.7806 - val_loss: 0.8768 - val_acc: 0.7746\n","Epoch 93/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4911 - acc: 0.7795\n","Epoch 00093: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 360ms/step - loss: 0.4911 - acc: 0.7795 - val_loss: 0.8451 - val_acc: 0.7480\n","Epoch 94/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4985 - acc: 0.7802\n","Epoch 00094: val_acc did not improve from 0.80438\n","165/165 [==============================] - 60s 363ms/step - loss: 0.4985 - acc: 0.7802 - val_loss: 0.8414 - val_acc: 0.7387\n","Epoch 95/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5206 - acc: 0.7592\n","Epoch 00095: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 360ms/step - loss: 0.5206 - acc: 0.7592 - val_loss: 0.8222 - val_acc: 0.7559\n","Epoch 96/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4840 - acc: 0.7905\n","Epoch 00096: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.4840 - acc: 0.7905 - val_loss: 0.7745 - val_acc: 0.7606\n","Epoch 97/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4965 - acc: 0.7757\n","Epoch 00097: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.4965 - acc: 0.7757 - val_loss: 0.8620 - val_acc: 0.7590\n","Epoch 98/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5021 - acc: 0.7761\n","Epoch 00098: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5021 - acc: 0.7761 - val_loss: 0.8286 - val_acc: 0.7715\n","Epoch 99/100\n","165/165 [==============================] - ETA: 0s - loss: 0.4974 - acc: 0.7857\n","Epoch 00099: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.4974 - acc: 0.7857 - val_loss: 0.8287 - val_acc: 0.7653\n","Epoch 100/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5002 - acc: 0.7804\n","Epoch 00100: val_acc did not improve from 0.80438\n","165/165 [==============================] - 59s 359ms/step - loss: 0.5002 - acc: 0.7804 - val_loss: 0.8281 - val_acc: 0.7668\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8OFLZdE_mFo9","colab_type":"code","outputId":"dce79093-17fa-4299-f9a3-5e445c8c6692","executionInfo":{"status":"ok","timestamp":1585578139075,"user_tz":-300,"elapsed":417850,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Evaluate the Best Saved Model\n","model = tf.keras.models.load_model('./saved Models/Pretrained-VGG16/normalized-best-model.h5')\n","loss, accuracy = model.evaluate(x=test_x, y=test_y_oneHot, batch_size=32, verbose=1)\n","print('Model Accuracy: {:0.2f}% | Model Loss: {:0.4f}'.format(accuracy*100, loss))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n","20/20 [==============================] - 389s 19s/step - loss: 0.6929 - acc: 0.7997\n","Model Accuracy: 79.97% | Model Loss: 0.6929\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7GdNu3XQCTU4","colab_type":"code","outputId":"ff16243f-ea9a-40d3-9e56-74f16ca5cdd6","executionInfo":{"status":"ok","timestamp":1585580979720,"user_tz":-300,"elapsed":1767,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}},"colab":{"base_uri":"https://localhost:8080/","height":611}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Purples')\n","\n","    plt.figure(figsize=(10, 8))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('GroundTruths')\n","    plt.xlabel('Predictions \\n Model Accuracy={:0.2f}% | Model Error={:0.2f}%'.format(accuracy*100, misclass*100))\n","    plt.savefig('./ReadMe Images/VGG16-cm.png', bbox_inches = \"tight\")\n","    plt.show()\n","\n","\n","# predictions = model.predict(x=test_x, batch_size=32)\n","# predictions = tf.keras.backend.argmax(predictions, axis=-1)\n","\n","# cm = confusion_matrix(test_y, predictions)\n","classes = ['Normal', 'Bacteria', 'Viral', 'COVID-19']\n","plot_confusion_matrix(cm=cm, normalize = False, target_names = classes, title= \"Confusion Matrix (Pretrained VGG16 )\")\n"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAApEAAAJSCAYAAACbV57RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLYPIlFJKKaXUbP8PbwGTnc+26EYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 720x576 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"j38CQQow0hZR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
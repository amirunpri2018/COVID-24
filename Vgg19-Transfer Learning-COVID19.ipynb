{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Vgg19-Transfer Learning-COVID19.ipynb","provenance":[],"authorship_tag":"ABX9TyO/CqU1KNI3JRDqQtCMPj6O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"205orS_uTymG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"4d14ed22-fedd-4138-c429-a0e98d094915","executionInfo":{"status":"ok","timestamp":1585573598666,"user_tz":-300,"elapsed":142385,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W2cDWTEWV-ZH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"168301b9-1a27-4c3f-bc4f-45dc1ca0e4ab","executionInfo":{"status":"ok","timestamp":1585573675661,"user_tz":-300,"elapsed":131929,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","\n","%cd '/content/drive/My Drive/GitHub Repositories/COVID-19'\n","\n","dataDir = './datasets/dataset 01/Numpy Files'\n","train_x = np.load(dataDir+'/train_images.npy')\n","train_y = np.load(dataDir+'/train_labels.npy')\n","test_x = np.load(dataDir+'/test_images.npy')\n","test_y = np.load(dataDir+'/test_labels.npy')\n","\n","print('Training Images: {} | Test Images: {}'.format(train_x.shape, test_x.shape))\n","print('Training Labels: {} | Test Labels: {}'.format(train_y.shape, test_y.shape))\n","\n","# Data Normalization\n","\n","print('Train: {} , {} | Test: {} , {}'.format(train_x.min(), train_x.max(), test_x.min(), test_x.max()))\n","\n","train_x/=255.0\n","test_x/=255.0\n","\n","print('Train: {} , {} | Test: {} , {}'.format(train_x.min(), train_x.max(), test_x.min(), test_x.max()))\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/GitHub Repositories/COVID-19\n","Training Images: (5310, 224, 224, 3) | Test Images: (639, 224, 224, 3)\n","Training Labels: (5310,) | Test Labels: (639,)\n","Train: 0.0 , 255.0 | Test: 0.0 , 255.0\n","Train: 0.0 , 1.0 | Test: 0.0 , 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YIcRVgArWDHL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"c9eacc2c-0a7f-4442-b54e-54936715d476","executionInfo":{"status":"ok","timestamp":1585573681778,"user_tz":-300,"elapsed":137305,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["from collections import Counter\n","# Class Mapping \n","print('0:Normal | 1:Bacteria | 2:Viral | 3:COVID-19')\n","\n","# Distribution of images in each class for Training-set\n","print(Counter(train_y))\n","\n","# Distribution of images in each class for Test-set\n","print(Counter(test_y))\n","\n","#Make Labels Categorical\n","train_y_oneHot = tf.one_hot(train_y, depth=4) \n","test_y_oneHot = tf.one_hot(test_y, depth=4)\n","\n","print('Training Labels: {} | Test Labels: {}'.format(train_y_oneHot.shape, test_y_oneHot.shape))\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["0:Normal | 1:Bacteria | 2:Viral | 3:COVID-19\n","Counter({1: 2540, 2: 1355, 0: 1349, 3: 66})\n","Counter({1: 246, 0: 234, 2: 149, 3: 10})\n","Training Labels: (5310, 4) | Test Labels: (639, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JZwpG0o0WRZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d3c3326a-54b0-44a4-eb08-4d75faff5ede","executionInfo":{"status":"ok","timestamp":1585573682937,"user_tz":-300,"elapsed":137758,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["# initialize the training data augmentation object\n","trainAug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")\n","\n","def VGG19_Model():\n","  # load the VGG16 network, ensuring the head FC layer sets are left off\n","  baseModel = tf.keras.applications.VGG19(weights=\"imagenet\", include_top=False, input_tensor=tf.keras.layers.Input(shape=(224, 224, 3)))\n","  # construct the head of the model that will be placed on top of the the base model\n","  output = baseModel.output\n","  output = tf.keras.layers.AveragePooling2D(pool_size=(4, 4))(output)\n","  output = tf.keras.layers.Flatten(name=\"flatten\")(output)\n","  output = tf.keras.layers.Dense(256, activation=\"relu\")(output)\n","  output = tf.keras.layers.Dropout(0.5)(output)\n","  output = tf.keras.layers.Dense(4, activation=\"softmax\")(output)\n","  # place the head FC model on top of the base model (this will become the actual model we will train)\n","  model = tf.keras.Model(inputs=baseModel.input, outputs=output)\n","  # loop over all layers in the base model and freeze them so they will not be updated during the first training process\n","  for layer in baseModel.layers:\n","    layer.trainable = False\n","  return model\n","\n","model = VGG19_Model()\n","# compile our model\n","print(\"[INFO] compiling model...\")\n","# initialize the initial learning rate, number of epochs to train for, and batch size\n","INIT_LR = 0.001\n","EPOCHS = 100\n","BATCHSIZE = 32\n","optimizer = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n","print(model.summary())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 1s 0us/step\n","[INFO] compiling model...\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","average_pooling2d (AveragePo (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 1028      \n","=================================================================\n","Total params: 20,156,740\n","Trainable params: 132,356\n","Non-trainable params: 20,024,384\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SUn0WZOCWd8I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"51889f4b-0d29-4baa-90c6-0e415fea162f"},"source":["modelPath = './saved Models/Pretrained-VGG19'\n","if not os.path.exists(modelPath):\n","  os.makedirs(modelPath)\n","  print('Model Directory Created')\n","else:\n","  print('Model Directory Already Exists')\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('./saved Models/Pretrained-VGG16/normalized-best-model.h5', monitor='val_acc',\n","                                                      verbose=1, save_best_only=True, mode='auto')\n","STEP_TRAIN = len(train_x) // BATCHSIZE\n","STEP_TEST = len(test_x) // BATCHSIZE\n","\n","modelHistory = model.fit(trainAug.flow(train_x, train_y_oneHot, batch_size=BATCHSIZE), epochs=100, verbose=1, callbacks=[model_checkpoint],\n","                         validation_data=(test_x, test_y_oneHot), shuffle = True, steps_per_epoch=STEP_TRAIN, validation_steps=STEP_TEST)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model Directory Created\n","Epoch 1/100\n","165/165 [==============================] - ETA: 0s - loss: 0.9237 - acc: 0.5992\n","Epoch 00001: val_acc improved from -inf to 0.65728, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 93s 564ms/step - loss: 0.9237 - acc: 0.5992 - val_loss: 0.8411 - val_acc: 0.6573\n","Epoch 2/100\n","165/165 [==============================] - ETA: 0s - loss: 0.7409 - acc: 0.6758\n","Epoch 00002: val_acc did not improve from 0.65728\n","165/165 [==============================] - 84s 508ms/step - loss: 0.7409 - acc: 0.6758 - val_loss: 0.8586 - val_acc: 0.6228\n","Epoch 3/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6941 - acc: 0.6976\n","Epoch 00003: val_acc improved from 0.65728 to 0.69171, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 85s 515ms/step - loss: 0.6941 - acc: 0.6976 - val_loss: 0.8374 - val_acc: 0.6917\n","Epoch 4/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6634 - acc: 0.7131\n","Epoch 00004: val_acc did not improve from 0.69171\n","165/165 [==============================] - 83s 501ms/step - loss: 0.6634 - acc: 0.7131 - val_loss: 0.7983 - val_acc: 0.6839\n","Epoch 5/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6500 - acc: 0.7209\n","Epoch 00005: val_acc did not improve from 0.69171\n","165/165 [==============================] - 82s 497ms/step - loss: 0.6500 - acc: 0.7209 - val_loss: 0.8812 - val_acc: 0.6228\n","Epoch 6/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6353 - acc: 0.7298\n","Epoch 00006: val_acc did not improve from 0.69171\n","165/165 [==============================] - 82s 499ms/step - loss: 0.6353 - acc: 0.7298 - val_loss: 0.8346 - val_acc: 0.6667\n","Epoch 7/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6250 - acc: 0.7397\n","Epoch 00007: val_acc improved from 0.69171 to 0.69797, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 82s 499ms/step - loss: 0.6250 - acc: 0.7397 - val_loss: 0.8080 - val_acc: 0.6980\n","Epoch 8/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6174 - acc: 0.7359\n","Epoch 00008: val_acc improved from 0.69797 to 0.71362, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 82s 497ms/step - loss: 0.6174 - acc: 0.7359 - val_loss: 0.8259 - val_acc: 0.7136\n","Epoch 9/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6043 - acc: 0.7419\n","Epoch 00009: val_acc did not improve from 0.71362\n","165/165 [==============================] - 82s 497ms/step - loss: 0.6043 - acc: 0.7419 - val_loss: 0.8137 - val_acc: 0.6729\n","Epoch 10/100\n","165/165 [==============================] - ETA: 0s - loss: 0.6048 - acc: 0.7376\n","Epoch 00010: val_acc improved from 0.71362 to 0.74648, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 83s 504ms/step - loss: 0.6048 - acc: 0.7376 - val_loss: 0.7575 - val_acc: 0.7465\n","Epoch 11/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5893 - acc: 0.7480\n","Epoch 00011: val_acc improved from 0.74648 to 0.78247, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 83s 502ms/step - loss: 0.5893 - acc: 0.7480 - val_loss: 0.6701 - val_acc: 0.7825\n","Epoch 12/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5837 - acc: 0.7438\n","Epoch 00012: val_acc did not improve from 0.78247\n","165/165 [==============================] - 82s 495ms/step - loss: 0.5837 - acc: 0.7438 - val_loss: 0.6548 - val_acc: 0.7746\n","Epoch 13/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5801 - acc: 0.7478\n","Epoch 00013: val_acc did not improve from 0.78247\n","165/165 [==============================] - 83s 503ms/step - loss: 0.5801 - acc: 0.7478 - val_loss: 0.8682 - val_acc: 0.6714\n","Epoch 14/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5869 - acc: 0.7488\n","Epoch 00014: val_acc did not improve from 0.78247\n","165/165 [==============================] - 81s 494ms/step - loss: 0.5869 - acc: 0.7488 - val_loss: 0.7871 - val_acc: 0.7496\n","Epoch 15/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5692 - acc: 0.7529\n","Epoch 00015: val_acc did not improve from 0.78247\n","165/165 [==============================] - 82s 495ms/step - loss: 0.5692 - acc: 0.7529 - val_loss: 0.7327 - val_acc: 0.7214\n","Epoch 16/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5693 - acc: 0.7548\n","Epoch 00016: val_acc did not improve from 0.78247\n","165/165 [==============================] - 81s 492ms/step - loss: 0.5693 - acc: 0.7548 - val_loss: 0.6660 - val_acc: 0.7731\n","Epoch 17/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5555 - acc: 0.7628\n","Epoch 00017: val_acc did not improve from 0.78247\n","165/165 [==============================] - 82s 496ms/step - loss: 0.5555 - acc: 0.7628 - val_loss: 0.7715 - val_acc: 0.7261\n","Epoch 18/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5691 - acc: 0.7569\n","Epoch 00018: val_acc did not improve from 0.78247\n","165/165 [==============================] - 81s 489ms/step - loss: 0.5691 - acc: 0.7569 - val_loss: 0.8576 - val_acc: 0.7152\n","Epoch 19/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5436 - acc: 0.7707\n","Epoch 00019: val_acc did not improve from 0.78247\n","165/165 [==============================] - 80s 486ms/step - loss: 0.5436 - acc: 0.7707 - val_loss: 0.6469 - val_acc: 0.7809\n","Epoch 20/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5499 - acc: 0.7675\n","Epoch 00020: val_acc improved from 0.78247 to 0.78560, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 83s 501ms/step - loss: 0.5499 - acc: 0.7675 - val_loss: 0.6779 - val_acc: 0.7856\n","Epoch 21/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5644 - acc: 0.7550\n","Epoch 00021: val_acc did not improve from 0.78560\n","165/165 [==============================] - 82s 495ms/step - loss: 0.5644 - acc: 0.7550 - val_loss: 0.7664 - val_acc: 0.7261\n","Epoch 22/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5623 - acc: 0.7529\n","Epoch 00022: val_acc did not improve from 0.78560\n","165/165 [==============================] - 82s 494ms/step - loss: 0.5623 - acc: 0.7529 - val_loss: 0.9143 - val_acc: 0.7230\n","Epoch 23/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5478 - acc: 0.7630\n","Epoch 00023: val_acc did not improve from 0.78560\n","165/165 [==============================] - 81s 490ms/step - loss: 0.5478 - acc: 0.7630 - val_loss: 0.7650 - val_acc: 0.7527\n","Epoch 24/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5495 - acc: 0.7643\n","Epoch 00024: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 484ms/step - loss: 0.5495 - acc: 0.7643 - val_loss: 0.9029 - val_acc: 0.6808\n","Epoch 25/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5522 - acc: 0.7622\n","Epoch 00025: val_acc did not improve from 0.78560\n","165/165 [==============================] - 81s 491ms/step - loss: 0.5522 - acc: 0.7622 - val_loss: 0.7356 - val_acc: 0.7465\n","Epoch 26/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5423 - acc: 0.7692\n","Epoch 00026: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 482ms/step - loss: 0.5423 - acc: 0.7692 - val_loss: 0.6946 - val_acc: 0.7621\n","Epoch 27/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5438 - acc: 0.7660\n","Epoch 00027: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 487ms/step - loss: 0.5438 - acc: 0.7660 - val_loss: 0.8329 - val_acc: 0.7183\n","Epoch 28/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5417 - acc: 0.7673\n","Epoch 00028: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 485ms/step - loss: 0.5417 - acc: 0.7673 - val_loss: 0.6326 - val_acc: 0.7825\n","Epoch 29/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5525 - acc: 0.7526\n","Epoch 00029: val_acc did not improve from 0.78560\n","165/165 [==============================] - 81s 488ms/step - loss: 0.5525 - acc: 0.7526 - val_loss: 0.6843 - val_acc: 0.7606\n","Epoch 30/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5288 - acc: 0.7692\n","Epoch 00030: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 485ms/step - loss: 0.5288 - acc: 0.7692 - val_loss: 0.9154 - val_acc: 0.6854\n","Epoch 31/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5253 - acc: 0.7732\n","Epoch 00031: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 486ms/step - loss: 0.5253 - acc: 0.7732 - val_loss: 0.7774 - val_acc: 0.7449\n","Epoch 32/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5422 - acc: 0.7683\n","Epoch 00032: val_acc did not improve from 0.78560\n","165/165 [==============================] - 79s 480ms/step - loss: 0.5422 - acc: 0.7683 - val_loss: 0.7625 - val_acc: 0.7355\n","Epoch 33/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5271 - acc: 0.7751\n","Epoch 00033: val_acc did not improve from 0.78560\n","165/165 [==============================] - 79s 481ms/step - loss: 0.5271 - acc: 0.7751 - val_loss: 0.7541 - val_acc: 0.7574\n","Epoch 34/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5412 - acc: 0.7620\n","Epoch 00034: val_acc did not improve from 0.78560\n","165/165 [==============================] - 79s 478ms/step - loss: 0.5412 - acc: 0.7620 - val_loss: 0.8607 - val_acc: 0.7199\n","Epoch 35/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5209 - acc: 0.7800\n","Epoch 00035: val_acc did not improve from 0.78560\n","165/165 [==============================] - 80s 484ms/step - loss: 0.5209 - acc: 0.7800 - val_loss: 0.7589 - val_acc: 0.7574\n","Epoch 36/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5347 - acc: 0.7706\n","Epoch 00036: val_acc did not improve from 0.78560\n","165/165 [==============================] - 81s 490ms/step - loss: 0.5347 - acc: 0.7706 - val_loss: 0.7366 - val_acc: 0.7606\n","Epoch 37/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5287 - acc: 0.7742\n","Epoch 00037: val_acc did not improve from 0.78560\n","165/165 [==============================] - 81s 493ms/step - loss: 0.5287 - acc: 0.7742 - val_loss: 0.7592 - val_acc: 0.7559\n","Epoch 38/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5196 - acc: 0.7725\n","Epoch 00038: val_acc improved from 0.78560 to 0.79343, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 83s 501ms/step - loss: 0.5196 - acc: 0.7725 - val_loss: 0.7365 - val_acc: 0.7934\n","Epoch 39/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5273 - acc: 0.7689\n","Epoch 00039: val_acc did not improve from 0.79343\n","165/165 [==============================] - 82s 499ms/step - loss: 0.5273 - acc: 0.7689 - val_loss: 0.9007 - val_acc: 0.7183\n","Epoch 40/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5201 - acc: 0.7791\n","Epoch 00040: val_acc did not improve from 0.79343\n","165/165 [==============================] - 83s 502ms/step - loss: 0.5201 - acc: 0.7791 - val_loss: 0.7771 - val_acc: 0.7449\n","Epoch 41/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5155 - acc: 0.7766\n","Epoch 00041: val_acc did not improve from 0.79343\n","165/165 [==============================] - 82s 498ms/step - loss: 0.5155 - acc: 0.7766 - val_loss: 0.7546 - val_acc: 0.7402\n","Epoch 42/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5174 - acc: 0.7721\n","Epoch 00042: val_acc did not improve from 0.79343\n","165/165 [==============================] - 81s 489ms/step - loss: 0.5174 - acc: 0.7721 - val_loss: 0.7271 - val_acc: 0.7700\n","Epoch 43/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5245 - acc: 0.7721\n","Epoch 00043: val_acc improved from 0.79343 to 0.79969, saving model to ./saved Models/Pretrained-VGG16/normalized-best-model.h5\n","165/165 [==============================] - 83s 504ms/step - loss: 0.5245 - acc: 0.7721 - val_loss: 0.6965 - val_acc: 0.7997\n","Epoch 44/100\n","165/165 [==============================] - ETA: 0s - loss: 0.5203 - acc: 0.7698\n","Epoch 00044: val_acc did not improve from 0.79969\n","165/165 [==============================] - 83s 500ms/step - loss: 0.5203 - acc: 0.7698 - val_loss: 0.7069 - val_acc: 0.7684\n","Epoch 45/100\n","127/165 [======================>.......] - ETA: 16s - loss: 0.5141 - acc: 0.7806"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wcqVJy66jAyM","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"black\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"black\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label \\n Accuracy={:0.2f}% \\n Classification Error={:0.2f}%'.format(accuracy*100, misclass*100))\n","    plt.show()\n","\n","\n","predictions = model.predict(x=test_x, batch_size=32)\n","predictions = tf.keras.backend.argmax(predictions, axis=-1)\n","\n","cm = confusion_matrix(test_y, predictions)\n","classes = ['Normal', 'Bacteria', 'Viral', 'COVID-19']\n","plot_confusion_matrix(cm=cm, normalize = True, target_names = classes, title= \"Normalized Confusion Matrix\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjROEFyOjEou","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}